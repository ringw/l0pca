{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a098eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from l0pca.bunch import rank_one_eigenvalues\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4ddac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 17:49:40.299663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:40.338319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:40.339153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:40.340095: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 17:49:40.343307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:40.344027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:40.344694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:41.237468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:41.238091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:41.238104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-11-11 17:49:41.238685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-11 17:49:41.238725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6002 MB memory:  -> device: 0, name: NVIDIA T1000 8GB, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "updates = tf.random.normal((1024 * 64, 1, 5))\n",
    "S = tf.sort(tf.random.uniform((1024 * 64, 1, 4)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4fc703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 17:49:41.886689: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1cb40c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-11 17:49:41.886729: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA T1000 8GB, Compute Capability 7.5\n",
      "2022-11-11 17:49:42.059944: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-11 17:49:42.686006: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-11 17:50:42.953575: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 412.07 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "491 ms ± 355 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rank_one_eigenvalues.eigenvalue_initial_estimate(updates, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590b0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 17:50:47.130432: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2022-11-11 17:50:47.130475: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2022-11-11 17:50:47.130557: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2022-11-11 17:50:47.150648: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:192] cuptiSubscribe: error 15: CUPTI_ERROR_NOT_INITIALIZED\n",
      "2022-11-11 17:50:47.150689: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-11 17:50:47.150695: E tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1715] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 6.1 s, total: 9.52 s\n",
      "Wall time: 9.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 17:50:56.630342: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-11-11 17:50:56.632494: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2022-11-11 17:50:56.632526: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2022-11-11 17:50:56.632548: E tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1807] function cupti_interface_->Finalize()failed with error \n",
      "2022-11-11 17:50:56.635089: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-11 17:50:56.635137: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2022-11-11 17:50:56.635145: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:521]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-11 17:50:56.636057: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2022-11-11 17:50:56.638495: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: bunch_logs/plugins/profile/2022_11_11_17_50_56\n",
      "\n",
      "2022-11-11 17:50:56.640845: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.trace.json.gz\n",
      "2022-11-11 17:50:56.644490: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: bunch_logs/plugins/profile/2022_11_11_17_50_56\n",
      "\n",
      "2022-11-11 17:50:56.645378: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.memory_profile.json.gz\n",
      "2022-11-11 17:50:56.645586: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: bunch_logs/plugins/profile/2022_11_11_17_50_56\n",
      "Dumped tool data for xplane.pb to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.xplane.pb\n",
      "Dumped tool data for overview_page.pb to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to bunch_logs/plugins/profile/2022_11_11_17_50_56/BIOL-XC-DANIEL.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.profiler.experimental.start('bunch_logs')\n",
    "for i in range(10):\n",
    "    rank_one_eigenvalues.eigenvalue_initial_estimate(\n",
    "        tf.random.normal((1024 * 64, 1, 5)),\n",
    "        tf.sort(tf.random.uniform((1024 * 64, 1, 4)), axis=-1))\n",
    "tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24186d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 1.64 s, total: 18.5 s\n",
      "Wall time: 18.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16384, 1, 5), dtype=float32, numpy=\n",
       "array([[[2.4361949e-02, 7.8926839e-02, 3.4906235e-01, 8.0338681e-01,\n",
       "         1.3403412e+00]],\n",
       "\n",
       "       [[4.0385788e-03, 8.6523294e-02, 2.5197539e-01, 7.5792348e-01,\n",
       "         2.0887709e+00]],\n",
       "\n",
       "       [[2.0235518e-02, 9.2225820e-02, 1.2658915e-01, 1.8146633e-01,\n",
       "         3.7116530e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2.7438787e-01, 6.1759007e-01, 6.5808648e-01, 6.6085601e-01,\n",
       "         1.0188031e+01]],\n",
       "\n",
       "       [[5.0325364e-02, 1.9631173e-01, 3.3604535e-01, 5.2069271e-01,\n",
       "         3.4417393e+00]],\n",
       "\n",
       "       [[1.7971445e-03, 2.2188175e-02, 1.8010223e-01, 2.0336613e-01,\n",
       "         1.3079982e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rank_one_eigenvalues.eigenvalue_initial_estimate(\n",
    "    tf.random.normal((1024 * 16, 1, 5)),\n",
    "    tf.sort(tf.random.uniform((1024 * 16, 1, 4)), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3124424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
